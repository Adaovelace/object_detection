# -*- coding: utf-8 -*-
"""algae.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lnVoW6-cwfBIjOYRM5lRnZwSqYPD0fdL
"""

import google.auth

from google.colab import auth
auth.authenticate_user()

import os
import glob
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score
from sklearn.preprocessing import LabelEncoder

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Define file path
file_path = "/content/drive/My Drive/algae_data_11"

import os
import glob
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score
from sklearn.preprocessing import LabelEncoder

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Define file path
file_path = "/content/drive/My Drive/algae_data_11"

# List of class names
classes = ['Prorocentrum', 'Nodularia', 'Oscillatoria', 'Karenia', 'Microcystis',
           'Skeletonema', 'Nostoc', 'nontoxic', 'Noctiluca', 'Gymnodinium',
           'Aphanizomenon', 'Anabaena']

# Get file paths and labels
filepaths = []
labels = []
for class_name in classes:
    class_files = glob.glob(os.path.join(file_path, class_name, '*.*'))
    filepaths.extend(class_files)
    labels.extend([class_name] * len(class_files))

# Create DataFrame
data = pd.DataFrame({'Filepath': filepaths, 'Label': labels})

# Shuffle the DataFrame
data = data.sample(frac=1).reset_index(drop=True)

# Display the first few rows of the DataFrame
print(data.head())

# Plot class distribution
plt.figure(figsize=(8, 6))
sns.countplot(y='Label', data=data, order=classes, palette='Dark2')
plt.xlabel('Count')
plt.title('Class Distribution')
plt.show()

# Train-test split
train, test = train_test_split(data, test_size=0.25, random_state=42)

# Data generators
train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input,
                                   rotation_range=30,
                                   horizontal_flip=True,
                                   vertical_flip=True,
                                   brightness_range=[0.4, 1.5],
                                   validation_split=0.2)

test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input)

# Flow from DataFrame
train_gen = train_datagen.flow_from_dataframe(
    dataframe=train,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    class_mode='categorical',
    batch_size=128,
    shuffle=True,
    seed=42,
    subset='training'
)

valid_gen = train_datagen.flow_from_dataframe(
    dataframe=train,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    class_mode='categorical',
    batch_size=128,
    shuffle=True,
    seed=42,
    subset='validation'
)

test_gen = test_datagen.flow_from_dataframe(
    dataframe=test,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    class_mode='categorical',
    batch_size=128,
    shuffle=False,
    seed=42
)

# Load pre-trained ResNet50 model
pretrained_model = ResNet50(
    input_shape=(224, 224, 3),
    include_top=False,
    weights='imagenet',
    pooling='avg'
)

# Freeze the pre-trained layers
pretrained_model.trainable = False

# Add custom classification layer
inputs = pretrained_model.input
outputs = Dense(len(classes), activation='softmax')(pretrained_model.output)
model = Model(inputs, outputs)

# Compile the model
model.compile(
    optimizer='Adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model
history = model.fit(
    train_gen,
    validation_data=valid_gen,
    epochs=10,
    batch_size=128,
    callbacks=[EarlyStopping(patience=3)]
)

# Save the model
model.save("algae_classification_model_2.h5")

# Plot training and validation accuracy
plt.figure(figsize=(10, 6))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

# Plot training and validation loss
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

name_class = os.listdir(file_path)
# name_class.remove('.DS_Store')
name_class

import matplotlib.pyplot as plt

filepaths = list(glob.glob(file_path+'/**/*.*'))

labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))
filepath = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')
data = pd.concat([filepath, labels], axis=1)
data = data.sample(frac=1).reset_index(drop=True)
data.head()

counts = data.Label.value_counts()
sns.barplot(x=counts.index, y=counts)
plt.xlabel('Type')
plt.xticks(rotation=90);

train, test = train_test_split(data, test_size=0.25, random_state=42)

fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(10,6), subplot_kw={'xticks':[],'yticks':[]})
for i, ax in enumerate(axes.flat):
    if i < len(data.Filepath):
        ax.imshow(plt.imread(data.Filepath[i]))
        ax.set_title(data.Label[i])
plt.tight_layout()
plt.show()

# Evaluate the model on test data
test_loss, test_accuracy = model.evaluate(test_gen, verbose=0)
print(f'Test Loss: {test_loss:.4f}')
print(f'Test Accuracy: {test_accuracy * 100:.2f}%')

# Generate predictions
predictions = model.predict(test_gen)
y_pred = np.argmax(predictions, axis=1)
y_true = test_gen.classes

# Classification report
print(classification_report(y_true, y_pred, target_names=classes))

# Confusion matrix
conf_mat = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',
            xticklabels=classes, yticklabels=classes)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Accuracy score
accuracy = accuracy_score(y_true, y_pred)
print(f'Accuracy: {accuracy:.2f}')

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import multilabel_confusion_matrix

auc_pred = model.predict(test_gen)

from sklearn.preprocessing import LabelBinarizer

# Convert labels to one-hot encoded format
label_binarizer = LabelBinarizer()
auc_y_true = label_binarizer.fit_transform(y_true)

# Convert predictions to probabilities
auc_pred = model.predict(test_gen)

# Calculate ROC curve and AUC for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(auc_y_true.shape[1]):
    fpr[i], tpr[i], _ = roc_curve(auc_y_true[:, i], auc_pred[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and AUC
fpr_micro, tpr_micro, _ = roc_curve(auc_y_true.ravel(), auc_pred.ravel())
roc_auc_micro = auc(fpr_micro, tpr_micro)

# Compute macro-average ROC curve and AUC
all_fpr = np.unique(np.concatenate([fpr[i] for i in range(auc_y_true.shape[1])]))
mean_tpr = np.zeros_like(all_fpr)
for i in range(auc_y_true.shape[1]):
    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
mean_tpr /= auc_y_true.shape[1]
fpr_macro = all_fpr
tpr_macro = mean_tpr
roc_auc_macro = auc(fpr_macro, tpr_macro)

# Plot ROC curves
plt.figure(figsize=(10, 8))
plt.plot(fpr_micro, tpr_micro, label=f'Micro-average ROC curve (AUC = {roc_auc_micro:0.2f})', color='deeppink', linestyle=':', linewidth=4)
plt.plot(fpr_macro, tpr_macro, label=f'Macro-average ROC curve (AUC = {roc_auc_macro:0.2f})', color='navy', linestyle=':', linewidth=4)

for i in range(auc_y_true.shape[1]):
    plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {i} (AUC = {roc_auc[i]:0.2f})')

plt.plot([0, 1], [0, 1], 'k--', linewidth=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()